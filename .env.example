# ============================================================================
# Environment Variables Template
# ============================================================================
# Copy this file to .env and fill in your actual values
# IMPORTANT: Never commit .env to version control!
# ============================================================================

# Google Cloud Platform Configuration
# Required: Your GCP Project ID
GCP_PROJECT_ID=your-gcp-project-id
REGION=your-region
BACKUP_BUCKET=gs://your-backup-bucket

# Optional: Path to service account JSON key file
# If not set, uses default application credentials (gcloud auth application-default login)
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json

# Kaggle API Credentials (for dataset download)
# ----------------------------------------------------------------------------
# Get your credentials from: https://www.kaggle.com/account
KAGGLE_USERNAME=your-kaggle-username
KAGGLE_KEY=your-kaggle-api-key

# BigQuery Configuration
# Database (BigQuery Project)
BQ_DATABASE=your-gcp-project-id

# BigQuery Dataset Names (Schemas)
# Note: dbt uses "raw" dataset for sources, "staging" for staging models
BQ_DATASET_RAW=staging
BQ_DATASET_STAGING=staging
BQ_DATASET_WAREHOUSE=warehouse

# Logging
# Optional: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ============================================================================
# Setup Instructions:
# 1. Copy this file: cp .env.example .env
# 2. Fill in your actual credentials in .env
# 3. Verify .env is in .gitignore (it should be)
# 4. Never commit .env to version control
# ============================================================================
